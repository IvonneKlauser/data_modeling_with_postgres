## Project: Data Modeling with Postgres

1. Discuss the purpose of this database in the context of the startup, Sparkify, and their analytical goals.
Sparkify is startup that runs a new music streaming app. Their data analytics team wants to do analyses on song listening behavior to further the business. Analyses could be done to improve user experience and sales. Until now access to data was difficult due to storage in JSON file. Goal is to provide data in way that enables data analysts.

2. State and justify your database schema design and ETL pipeline.
As described in the Udacity Data Modeling course, the star schema is used to model the data since data analyses on song listening data is the goal. The star schema simplifies queries.
Table songlpays is the fact table while user, songs, artists, time and users are the dimension tables (information to answer business questions).


**Table songplays:**
Records in log data associated with song plays i.e. records with page NextSong
Fact table with references to artists, songs, time and users

**Table users:**
Users in the app
Dimension table with user_id ad PRIMARY KEY which identifies a user
Information about users can change. E.g. a user could switch from level 'free' to 'paid' or change the last name

**Table songs:**
Songs in music database
Dimension table
Information on songs do not change over time

**Table time:**
Timestamps of records in songplays broken down into specific units
Dimension table
Information on songs do not change over time

**Table artists:**
Artists in music database
Dimension table
Information about artists can change. E.g. name or location can change

**ETL pipeline**
Song_data JSON files populate songs and artists
Log data JSON files populate time table, users and songplays. For songplays song_id and artist_id is queried from respective tables.

3. Files
**Song dataset (as per project specifications)**
Song data is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID

**Log dataset (as per project specifications)**
Log files are in JSON format generated by event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.
The log files in the dataset you'll be working with are partitioned by year and month.

**create_tables**
Drops and creates tables. Handels inserts

**etl.py**
Reads JSON files and populated database tables

4. Run python scripts
Open Jupyter
File - Console - Python 3 - Select
!python create_tables.py
!python etl.py